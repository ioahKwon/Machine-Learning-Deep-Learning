{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[머신러닝과딥러닝] Week_10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ioahKwon/Machine-Learning-Deep-Learning/blob/master/%5B%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%EA%B3%BC%EB%94%A5%EB%9F%AC%EB%8B%9D%5D_Week_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKETxdFzoFAg",
        "colab_type": "text"
      },
      "source": [
        "# **[머신러닝과딥러닝] 수업 정리 Week #10**\n",
        "\n",
        "### _2020.08._ SKKU Lecture Summary by IOAH\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz6qQ2cIg-QO",
        "colab_type": "text"
      },
      "source": [
        "### 1. Colab 환경에서 MNIST 데이터 예측을 위한 MLP 모형 설계"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bmUcMKohD_G",
        "colab_type": "text"
      },
      "source": [
        "이전 과제까지는 jupyter notebook을 이용해서 과제를 수행했지만 이번부터는 Google colab을 이용하여 실습을 진행하도록 하겠다. 우선 구글 드라이브에 데이터 파일을 업로드하고 COLAB과 드라이브를 연동해준다. 그 후 런타임 유형을 GPU로 설정해준다. 원래는 케라스 라이브러리에서 바로 MNIST 데이터를 불러올 수 있으나, 이번 실습에서는 연결된 구글 드라이브에 미리 업로드했던 MNIST 데이터를 로드한다. 이번 실습은 MLP의 전체적인 구조 및 작동 원리를 알아보기 위해 라이브러리를 사용하지 않고 클래스와 함수를 이용해 직접 정의해본다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0p_O5Alu3Z_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "382dac2f-5cd2-4f47-958a-b05bc98eeb44"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsrtFxwjxgb5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ec29dfd-c446-449d-97c7-273fd8ec85fe"
      },
      "source": [
        "a='hello colab'\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B75Zl_NnhJ8-",
        "colab_type": "text"
      },
      "source": [
        "잘 동작하는 것을 확인할 수 있다. 그다음 60000개의 mnist train data와 10000개의 mnist test data를 불러오고 matplotlib와 numpy를 이용하여 데이터를 시각화해본다. Numpy를 통해 픽셀 정보를 일렬로 나열하고 이를 다시 28x28로 바꾼다. Gray scale 이미지는 아래와 같다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7S1Feqcv_Ahu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#mnist_train(60000개)과 mnist_test(10000개) 데이터를 각각 불러온다.\n",
        "data_file = open(\"/content/gdrive/My Drive/data/mnist_train.csv\", \"r\") #연결되어 있는 구글 드라이브에 업로드했던 데이터를 코랩 환경으로 불러오는 코드\n",
        "training_data = data_file.readlines()\n",
        "data_file.close()\n",
        "\n",
        "test_data_file = open(\"/content/gdrive/My Drive/data/mnist_test.csv\", \"r\")\n",
        "test_data = test_data_file.readlines()\n",
        "test_data_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPmQ7QTzFlsi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "3cee986d-0cfb-47fa-85a7-e2281a8cee2a"
      },
      "source": [
        "#matplotlib과 numpy라이브러리를 불러온 후 데이터 하나를 시각화해본다.\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "t = np.asfarray(training_data[0].split(\",\"))\n",
        "\n",
        "# 일렬로 늘어진 픽셀정보를 28x28 행렬로 바꾼다\n",
        "n = t[1:].reshape(28,28)\n",
        "\n",
        "plt.imshow(n, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcmWF7UuhNdQ",
        "colab_type": "text"
      },
      "source": [
        "우선 먼저 클래스를 선언한 후 input_layer, hidden_layer, output_layer 각각의 노드 개수를 인자로 입력받을 수 있도록 매개변수를 초기화한다. 이번 실습에서는 hidden layer를 3개 쌓아보도록 하자. 그 다음 층별 가중치 값들을 레이어의 층 수에 맞춰 랜덤으로 초기화하고 forward 방향으로 예측을 수행하게 될 predict() 함수를 정의한다. Activation function은 차례로 sigmoid, tanh, sigmoid, softmax를 쓰도록 한다. 그리고 training data로 학습을 진행하도록 모델을 설계한다. 이 함수는 입력받은 epoch 동안 지정해준 learning rate를 통해 각 층의 activation function에 맞춰 feed-forward propagation과 back propagation을 수행하고 가중치가 계속 업데이트 되도록 코드를 짠다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABKOv_avhYjV",
        "colab_type": "text"
      },
      "source": [
        "그 후 현재 neural network의 accuracy를 출력하는 함수를 정의한다. 이 함수를 통해 test 데이터에 대한 예측 정확도를 출력하면서 학습이 이루어짐에 따른 정확도 변화를 볼 수 있다. 이후 sigmoid와 normalize, tanh, softmax함수를 정의한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjRipzjxFt49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeepNeuralNetwork:\n",
        "    #DeepNeuralNetwork 클래스를 initialize\n",
        "    def __init__(self, input_layers, hidden_layer_1, hidden_layer_2, hidden_layer_3, output_layers):\n",
        "        self.inputs = input_layers\n",
        "        self.hidden_1 = hidden_layer_1\n",
        "        self.hidden_2 = hidden_layer_2\n",
        "        self.hidden_3 = hidden_layer_3\n",
        "        self.outputs = output_layers\n",
        "        self.test_data = None\n",
        "\n",
        "        #가중치 값들을 모두 랜덤으로 초기화\n",
        "        self.w_ih = np.random.randn(self.inputs, self.hidden_1) / np.sqrt(self.inputs/2)\n",
        "        self.w_hh_12 = np.random.randn(self.hidden_1, self.hidden_2) / np.sqrt(self.hidden_1/2)\n",
        "        self.w_hh_23 = np.random.randn(self.hidden_2, self.hidden_3) / np.sqrt(self.hidden_2/2)\n",
        "        self.w_ho = np.random.randn(self.hidden_3, self.outputs) / np.sqrt(self.hidden_3/2)\n",
        "\n",
        "    # feed-forward를 진행한다.\n",
        "    def predict(self, x):\n",
        "        # 문자열을 float array로 바꾸는 과정\n",
        "        data = self.normalize(np.asfarray(x.split(',')))\n",
        "\n",
        "        # 0번은 레이블이므로 제외\n",
        "        data = data[1:]\n",
        "\n",
        "        #3개의 은닉층(2개의 sigmoid와 1개의 tanh)과 하나의 출력층(softmax)\n",
        "        layer_1 = self.sigmoid(np.dot(data, self.w_ih))\n",
        "        layer_2 = self.tanh(np.dot(layer_1, self.w_hh_12))\n",
        "        layer_3 = self.sigmoid(np.dot(layer_2, self.w_hh_23))\n",
        "        output = self.softmax(np.dot(layer_3, self.w_ho))\n",
        "        return output\n",
        "\n",
        "    # training_data로 학습 진행\n",
        "    def train(self, training_data, learning_rate, epoch):\n",
        "        for ech in range(0, epoch):\n",
        "            for i, x in enumerate(training_data):\n",
        "                target = np.array(np.zeros(self.outputs) + learning_rate, ndmin=2)\n",
        "                target[0][int(x[0])] = 1-learning_rate\n",
        "                x = self.normalize(np.asfarray(x.split(\",\")))\n",
        "\n",
        "                # feed-forward propagation\n",
        "                layer1 = self.sigmoid(np.dot(x[1:], self.w_ih))\n",
        "                layer2 = self.tanh(np.dot(layer1, self.w_hh_12))\n",
        "                layer3 = self.sigmoid(np.dot(layer2, self.w_hh_23))\n",
        "                layer4 = self.softmax(np.dot(layer3, self.w_ho))\n",
        "\n",
        "                # back propagation\n",
        "                layer4_reverse = (target - layer4)\n",
        "                layer3_reverse = layer4_reverse.dot(self.w_ho.T) * (layer3 * (1 - layer3))\n",
        "                layer2_reverse = layer3_reverse.dot(self.w_hh_23.T) * (1 - layer2) * (1 + layer2)\n",
        "                layer1_reverse = layer2_reverse.dot(self.w_hh_12.T) * (layer1 * (1 - layer1))\n",
        "\n",
        "                # weight update\n",
        "                self.w_ho = self.w_ho + learning_rate * layer4_reverse.T.dot(np.array(layer3, ndmin=2)).T\n",
        "                self.w_hh_23 = self.w_hh_23 + learning_rate * layer3_reverse.T.dot(np.array(layer2, ndmin=2)).T\n",
        "                self.w_hh_12 = self.w_hh_12 + learning_rate * layer2_reverse.T.dot(np.array(layer1, ndmin=2)).T\n",
        "                self.w_ih = self.w_ih + learning_rate * layer1_reverse.T.dot(np.array(x[1:], ndmin=2)).T\n",
        "\n",
        "                #2000개에 한 번씩 accuracy 출력\n",
        "                if i % 2000 == 0 :\n",
        "                    self.print_accuracy()\n",
        "\n",
        "    # 현재 neural network의 accuracy를 출력한다.\n",
        "    def print_accuracy(self):\n",
        "        matched = 0\n",
        "\n",
        "        for x in self.test_data:\n",
        "            label = int(x[0])\n",
        "            predicted = np.argmax(self.predict(x))\n",
        "            if label == predicted :\n",
        "                matched = matched + 1\n",
        "        print('accuracy : {0}'.format(matched/len(self.test_data)))\n",
        "\n",
        "    #sigmoid함수 정의\n",
        "    def sigmoid(self, x):\n",
        "        return 1.0/(1.0 + np.exp(-x))\n",
        "\n",
        "    #feature scaling을 위한 normalize 함수 정의\n",
        "    def normalize(self, x):\n",
        "        return (x / 255.0) * 0.99 + 0.01\n",
        "    \n",
        "    #tanh함수 정의\n",
        "    def tanh(self, x):\n",
        "        return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
        "        \n",
        "    #softmax함수 정의\n",
        "    def softmax(self, x):\n",
        "        e_x = np.exp(x - np.max(x))\n",
        "        return e_x / e_x.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ftWOSnZhePh",
        "colab_type": "text"
      },
      "source": [
        "이를 통해 학습을 돌리면 다음과 같은 accuracy를 얻을 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6olNEFcjGApZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "710dd575-c108-420b-9bdc-91206b79b301"
      },
      "source": [
        "#input layer, hidden layer 1, 2, 3, output layer의 노드 수를 각각 784, 100, 100, 100, 10개로 설정\n",
        "network = DeepNeuralNetwork(784, 100, 100, 100, 10)\n",
        "network.test_data = test_data\n",
        "#learning rate은 0.01, epoch는 1로 설정\n",
        "network.train(training_data, 0.01, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy : 0.0974\n",
            "accuracy : 0.5862\n",
            "accuracy : 0.8055\n",
            "accuracy : 0.8391\n",
            "accuracy : 0.8497\n",
            "accuracy : 0.8657\n",
            "accuracy : 0.8789\n",
            "accuracy : 0.8076\n",
            "accuracy : 0.8849\n",
            "accuracy : 0.8804\n",
            "accuracy : 0.876\n",
            "accuracy : 0.8826\n",
            "accuracy : 0.8983\n",
            "accuracy : 0.8891\n",
            "accuracy : 0.8909\n",
            "accuracy : 0.8781\n",
            "accuracy : 0.9097\n",
            "accuracy : 0.9084\n",
            "accuracy : 0.8837\n",
            "accuracy : 0.9036\n",
            "accuracy : 0.9004\n",
            "accuracy : 0.9091\n",
            "accuracy : 0.9159\n",
            "accuracy : 0.9068\n",
            "accuracy : 0.9171\n",
            "accuracy : 0.9237\n",
            "accuracy : 0.9132\n",
            "accuracy : 0.9157\n",
            "accuracy : 0.9008\n",
            "accuracy : 0.9159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75Q5BfjchhhC",
        "colab_type": "text"
      },
      "source": [
        "결과를 통해 볼 수 있듯이 MNIST test set에 대한 최종 classification accuracy는 0.916 즉 91.6%의 높은 정확도를 가진다는 것을 알 수 있다. "
      ]
    }
  ]
}