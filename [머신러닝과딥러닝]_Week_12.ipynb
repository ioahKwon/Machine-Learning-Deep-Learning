{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[머신러닝과딥러닝] Week_12.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ioahKwon/Machine-Learning-Deep-Learning/blob/master/%5B%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%EA%B3%BC%EB%94%A5%EB%9F%AC%EB%8B%9D%5D_Week_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKETxdFzoFAg",
        "colab_type": "text"
      },
      "source": [
        "# **[머신러닝과딥러닝] 수업 정리 Week #12**\n",
        "\n",
        "### _2020.08._ SKKU Lecture Summary by IOAH\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rypjnkntl2-b",
        "colab_type": "text"
      },
      "source": [
        "### 1. Convolutional Neural Networks를 이용한 MNIST DATASET 분류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAenYfNXmCX5",
        "colab_type": "text"
      },
      "source": [
        "이번에는 CNN을 이용하여 MNIST 데이터를 분류하고 CNN의 구조, 파라미터 등을 바꿔가며 성능의 변화를 확인해보도록 하자. 실습을 위해 필요한 module을 import해주고 미리 hyper-parameter를 선언해둔다. 그 후 데이터를 로드하고 이를 trainset과 test set으로 분할시킨다. 이후 데이터 전처리 과정을 거친다. 위 과정은 아래와 같다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvfvXCxjEMAK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cdcd7095-6165-4b18-dc86-d6cb325a01aa"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfDc-NmSEwke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epoch = 12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fog3rl1EE3rj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows, img_cols = 28,28\n",
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
        "if K.image_data_format() == 'channels_first':\n",
        "  x_train = x_train.reshape(x_train.shape[0],1,img_rows,img_cols)\n",
        "  x_test = x_test.reshape(x_test.shape[0],1,img_rows,img_cols)\n",
        "  input_shape = (1,img_rows,img_cols)\n",
        "else: \n",
        "  x_train = x_train.reshape(x_train.shape[0],img_rows,img_cols,1)\n",
        "  x_test = x_test.reshape(x_test.shape[0],img_rows,img_cols,1)\n",
        "  input_shape = (img_rows,img_cols,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7cdn-QJFg_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train=x_train.astype('float32')/255\n",
        "x_test=x_test.astype('float32')/255\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train,num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test,num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkdAM_R8mH40",
        "colab_type": "text"
      },
      "source": [
        "그 후 model을 sequential()을 이용해 쌓는다. Conv2D를 통해 CNN Layer를 쌓고 maxpooling layer를 통해 pooling layer를 쌓는다. 그 후 0.25로 dropout layer를 overfitting을 막기 위해 쌓으며 이를 flatten함수를 통해 평탄화시키고 Fully connected layer로 activation function은 relu로, dropout 비율은 0.5, output layer의 activation function은 softmax로 쌓아서 모델을 완성한다.\n",
        "\n",
        "또한 모델에 사용될 loss function은 categorical_crossentropy로 주고 optimizer는 Adadelta로 주기로 하자. 평가지표는 accuracy로 정한다. \n",
        "\n",
        "이후 모델은 train set에 대해 학습시킨다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_okczofFFqvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3,3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wABI-tMdGMCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqPAJr_yGZqS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "864a2bd3-fc8a-4388-bb6d-05bb436f745b"
      },
      "source": [
        "model.fit(x_train,y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs = epoch,\n",
        "          verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.3408 - accuracy: 0.8971\n",
            "Epoch 2/12\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1399 - accuracy: 0.9584\n",
            "Epoch 3/12\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.1049 - accuracy: 0.9689\n",
            "Epoch 4/12\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0900 - accuracy: 0.9726\n",
            "Epoch 5/12\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.0794 - accuracy: 0.9762\n",
            "Epoch 6/12\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0708 - accuracy: 0.9781\n",
            "Epoch 7/12\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.0639 - accuracy: 0.9803\n",
            "Epoch 8/12\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0601 - accuracy: 0.9818\n",
            "Epoch 9/12\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0548 - accuracy: 0.9833\n",
            "Epoch 10/12\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0527 - accuracy: 0.9837\n",
            "Epoch 11/12\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0491 - accuracy: 0.9847\n",
            "Epoch 12/12\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0480 - accuracy: 0.9847\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fc2dbff8dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fkPFWRCGove",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "415dbb60-3469-462e-e8b5-e33cf44f8edf"
      },
      "source": [
        "score=model.evaluate(x_test,y_test,verbose=0)\n",
        "print('Test loss : ',score[0])\n",
        "print('Test acc : ',score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss :  0.0369082065519935\n",
            "Test acc :  0.9873999953269958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TPlVPQqmOBV",
        "colab_type": "text"
      },
      "source": [
        "결과가 꽤 잘 나온 것을 확인할 수 있다. 저번 11주차 실습에 비해서 꽤 성능이 향상됐음을 볼 수 있다.\n",
        "\n",
        "CNN 모델의 성능을 향상시키기 위해선 무엇이 또 필요할까? 우선 CNN LAYER를 한층 더 쌓아보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy5nVwVkHHph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Conv2D(32, kernel_size=(3,3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model2.add(Conv2D(32,(3,3),activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(128, activation='relu'))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxsuuxxkH8rN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "35d47230-f741-4fbd-b7b3-7347f9a9deea"
      },
      "source": [
        "model2.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "model2.fit(x_train,y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs = epoch,\n",
        "          verbose=1)\n",
        "score=model2.evaluate(x_test,y_test,verbose=0)\n",
        "print('Test loss : ',score[0])\n",
        "print('Test acc : ',score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.2990 - accuracy: 0.9079\n",
            "Epoch 2/12\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1018 - accuracy: 0.9696\n",
            "Epoch 3/12\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0744 - accuracy: 0.9779\n",
            "Epoch 4/12\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0633 - accuracy: 0.9805\n",
            "Epoch 5/12\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0574 - accuracy: 0.9831\n",
            "Epoch 6/12\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0478 - accuracy: 0.9855\n",
            "Epoch 7/12\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0461 - accuracy: 0.9866\n",
            "Epoch 8/12\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0426 - accuracy: 0.9871\n",
            "Epoch 9/12\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0394 - accuracy: 0.9882\n",
            "Epoch 10/12\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0361 - accuracy: 0.9888\n",
            "Epoch 11/12\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0354 - accuracy: 0.9891\n",
            "Epoch 12/12\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0341 - accuracy: 0.9899\n",
            "Test loss :  0.02716255957569083\n",
            "Test acc :  0.9907000064849854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpQwhoV3mrWr",
        "colab_type": "text"
      },
      "source": [
        "그러면 Train set에 대해선 무려 98.9%, test set에 대해선 99.1%의 경이로운 정확도를 보인다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOFpNUYKnDl5",
        "colab_type": "text"
      },
      "source": [
        "이외에도 Filter size등 다른 매개변수를 조금만 조정해주면 test set의 accuracy가 많이 올라가는 것을 확인할 수 있다.\n",
        "\n",
        "따라서 적절하게 매개변수를 조절해주거나 또는 CNN Layer를 더 deep 하게 쌓아주면 성능이 올라감을 확인할 수 있다.\n"
      ]
    }
  ]
}